# Mnemos Implementation Plan

> Parseable task checklist for the autonomous build loop.
> Format: `- [ ] P{phase}.{num}: {description}` (unchecked = pending, checked = done)

## Phase 1: Foundation

- [x] P1.1: Scaffold project structure -- Create docker-compose.yml (all 5 services: caddy, frontend, backend, qdrant, ollama), Caddyfile, .env.example, .gitignore, backend/Dockerfile, backend/requirements.txt, frontend/Dockerfile, frontend/package.json
- [x] P1.2: Backend core -- Create backend/app/__init__.py, main.py (FastAPI with CORS, lifespan), config.py (Pydantic Settings), db.py (SQLite + SQLModel engine/session), routers/health.py
- [x] P1.3: Memory model and CRUD -- Create backend/app/models/__init__.py, models/memory.py (Memory SQLModel, plaintext initially), routers/memories.py (full CRUD: POST, GET list, GET by id, PUT, DELETE)
- [x] P1.4: Frontend scaffold -- Create frontend/vite.config.ts, tailwind.config.js, tsconfig.json, index.html, src/main.tsx, src/App.tsx (React Router shell with Layout), src/components/Layout.tsx (nav sidebar), src/types/index.ts
- [x] P1.5: Frontend capture and timeline -- Create frontend/src/services/api.ts (fetch wrapper for backend), src/components/Capture.tsx (text input form), src/components/Timeline.tsx (chronological memory list), src/components/MemoryDetail.tsx (view/edit single memory)
- [x] P1.6: Phase 1 integration test -- Verify docker compose build succeeds, all services start, health endpoint returns 200, can create and list memories via API, frontend renders and connects to backend

## Phase 2: The Shield

- [x] P2.1: Encryption service -- Create backend/app/services/__init__.py, services/encryption.py (AES-256-GCM envelope encryption with DEK/KEK, HKDF key derivation, HMAC search tokens), backend/app/utils/__init__.py, utils/crypto.py (Argon2id key derivation, low-level primitives)
- [x] P2.2: Auth system -- Create backend/app/routers/auth.py (passphrase-based auth: derive master key client-side, verify via HMAC, JWT session tokens with 15min access + 7day refresh), backend/app/models/auth.py (session model), backend/app/dependencies.py (FastAPI deps for auth + encryption service injection)
- [x] P2.3: Client-side crypto -- Create frontend/src/services/crypto.ts (ClientCrypto class: Argon2id via argon2-browser WASM, HKDF key derivation, AES-256-GCM encrypt/decrypt with DEK/KEK envelope, lock/unlock/wipe), frontend/src/hooks/useEncryption.ts (key lifecycle, auto-lock on timeout), frontend/src/hooks/useAuth.ts (session management)
- [x] P2.4: Login UI and encrypted flow -- Create frontend/src/components/Login.tsx (passphrase entry, derive key, authenticate), modify Capture.tsx and Timeline.tsx to encrypt before send and decrypt after receive, add auth guards to all routes
- [x] P2.5: Shield integration test -- Verify passphrase login works end-to-end, create a memory via UI, inspect SQLite database to confirm all content fields are ciphertext (not plaintext), verify session timeout locks vault, write backend/tests/test_encryption.py

## Phase 3: The Vault

- [x] P3.1: Vault service -- Create backend/app/services/vault.py (age encryption via pyrage, file storage in data/vault/YYYY/MM/{uuid}.age, retrieve and decrypt, integrity verification with SHA-256)
- [x] P3.2: Preservation and ingestion -- Create backend/app/services/preservation.py (format conversion: JPEG→PNG, MP3→FLAC, DOCX→PDF/A+MD, HTML→MD using Pillow/ffmpeg/pandoc), backend/app/services/ingestion.py (content type detection, processing pipeline, coordinate encryption+vault+preservation)
- [x] P3.3: Ingest API and source model -- Create backend/app/models/source.py (Source SQLModel with vault_path, mime_type, preservation_format, per-file DEK), backend/app/routers/ingest.py (POST /api/ingest multipart upload), backend/app/routers/vault.py (GET file from vault, decrypt and serve)
- [x] P3.4: Enhanced capture UI -- Modify frontend/src/components/Capture.tsx to add drag-and-drop file upload zone, voice recorder (MediaRecorder API), photo capture (camera API), URL import field. Show upload progress and preservation status.
- [x] P3.5: Vault integration test -- Verify file upload works end-to-end, uploaded JPEG is stored as data/vault/YYYY/MM/{uuid}.age, file can be decrypted and is a valid lossless PNG conversion, write backend/tests/test_vault.py and backend/tests/test_ingestion.py

## Phase 4: The Cortex

- [x] P4.1: Embedding service -- Create backend/app/services/embedding.py (text chunking with overlap, generate embeddings via Ollama nomic-embed-text, store vectors in Qdrant with encrypted chunk payloads), ensure Qdrant collection is initialized on startup
- [x] P4.2: RAG and LLM services -- Create backend/app/services/rag.py (query embedding, top-K retrieval from Qdrant, decrypt chunks, build prompt with context, generate answer via LLM), backend/app/services/llm.py (Ollama abstraction: generate, stream, model management, optional cloud API fallback)
- [x] P4.3: Connection service -- Create backend/app/services/connections.py (find similar memories via embedding similarity, ask LLM to explain relationships, create Connection records), backend/app/models/connection.py (Connection SQLModel), backend/app/services/search.py (blind index HMAC search + vector search fusion, ranked results)
- [x] P4.4: Search and connection models -- Create backend/app/models/search_token.py (SearchToken SQLModel for blind index), backend/app/routers/search.py (GET /api/search with query, filters, pagination), backend/app/routers/cortex.py (connection CRUD, trigger re-analysis)
- [x] P4.5: Chat API and worker -- Create backend/app/routers/chat.py (WebSocket endpoint for streaming RAG chat), backend/app/worker.py (background job processor: embedding generation, connection discovery, heartbeat checks on new memory ingest)
- [x] P4.6: AI frontend -- Create frontend/src/components/Chat.tsx (WebSocket chat UI with streaming responses, source citations), frontend/src/components/Search.tsx (search with filters, result cards), frontend/src/components/Graph.tsx (D3.js force-directed graph of memory connections)
- [x] P4.7: Cortex integration test -- Verify embedding pipeline works (add memories, check Qdrant has vectors), search returns results, chat answers questions with source citations, connection graph renders, write backend/tests/test_search.py

## Phase 5: The Testament

- [x] P5.1: Shamir service -- Create backend/app/services/shamir.py (SLIP-39 key splitting: 3-of-5 threshold, mnemonic word shares, reconstruct from K shares), scripts/shamir-split.py (CLI tool), scripts/shamir-combine.py (CLI tool)
- [x] P5.2: Heartbeat service -- Create backend/app/services/heartbeat.py (dead man's switch: generate challenge, verify check-in with HMAC, escalation timeline at 30/45/60/75/90 days, alert dispatch), backend/app/models/heartbeat.py (Heartbeat and HeartbeatAlert SQLModels)
- [x] P5.3: Testament API -- Create backend/app/routers/heartbeat.py (GET challenge, POST check-in, GET status), backend/app/routers/testament.py (heir configuration, Shamir share metadata, heir-mode activation with read-only access + chat)
- [x] P5.4: Testament UI -- Create frontend/src/components/Heartbeat.tsx (monthly check-in button, days remaining, alert history), frontend/src/components/Testament.tsx (Shamir share management, heir list, inheritance status), frontend/src/components/Settings.tsx (system config, encryption status, backup status)
- [x] P5.5: Testament integration test -- Verify shamir-split.py generates 5 shares, any 3 reconstruct the key, 2 shares fail, heartbeat check-in resets timer, simulated 30-day gap triggers reminder, write backend/tests/test_shamir.py and backend/tests/test_heartbeat.py

## Phase 6: Hardening

- [x] P6.1: Backup and restore -- Create scripts/backup.sh (3-2-1-1-0 with restic: SQLite safe backup, local + B2 + S3 cold, verify, prune), scripts/restore.sh (verified restore from any restic repo)
- [x] P6.2: Migration and init -- Create scripts/migrate.sh (tar + sha256 bundle, instructions for new server), scripts/init.sh (first-time setup wizard: generate salt, create .env, pull Docker images, initialize DB, pull Ollama models)
- [x] P6.3: Monitoring and Makefile -- Create scripts/health-check.sh (cron-friendly: check all services, DB integrity, vault integrity, disk space, alert on failure), Makefile (targets: up, down, backup, restore, health, logs, shell, migrate, init)
- [x] P6.4: Documentation -- Create README.md (quick start, architecture overview, deployment guide), RECOVERY.md (total reconstruction guide for Shamir share holders, step-by-step with no assumed knowledge)
- [x] P6.5: Full test suite -- Create backend/tests/conftest.py (shared fixtures: test DB, test encryption keys, mock services), expand all test files with edge cases, add integration tests that verify the full pipeline end-to-end, docker-compose.test.yml for isolated test environment

## Discovery Round 2

- [x] D2.1: Fix insecure master key wiping in auth_state.py -- `wipe_master_key()` uses `del key` which only removes the reference; the bytes remain in process memory. Must overwrite with zeros in-place (`bytearray` swap or `ctypes.memset`) before deleting. Same issue in `wipe_all()` which calls `.clear()` without zeroing values first.
- [x] D2.2: Validate encryption algo/version on decrypt in encryption.py -- `EncryptionService.decrypt()` ignores `envelope.algo` and `envelope.version`, so a future envelope with a different algorithm would silently decrypt with the wrong method. Add validation that algo/version match supported values before decrypting; raise a clear error for unsupported versions (crypto-agility gate).
- [x] D2.3: Implement URL ingestion in ingestion.py -- `ingest_url()` raises `NotImplementedError`. ARCHITECTURE.md specifies HTML/webpage ingestion via readability + pandoc conversion to Markdown. Implement using httpx for fetching and readability-lxml (or similar) for content extraction, storing both the original HTML in the vault and a Markdown extract as the memory content.
- [x] D2.4: Add retry mechanism and failure tracking to background worker -- `worker.py` silently discards failed jobs (embedding, connection discovery, search tokenization) with only a log entry. Add a job status model (pending/processing/succeeded/failed), persist failed jobs to the DB, and implement configurable retry with exponential backoff. Surface failures via the health endpoint.
- [x] D2.5: Add `nodev` to tmpfs mount and pin Ollama image version in docker-compose.yml -- tmpfs at `/app/tmp` is missing the `nodev` flag (should be `size=256m,noexec,nosuid,nodev`). Ollama uses `latest` tag which can break builds unexpectedly; pin to a specific version. Also add JSON-file logging driver with max-size/max-file limits to prevent unbounded log growth.
- [x] D2.6: Create docker-compose.prod.yml with resource limits -- ARCHITECTURE.md references `docker-compose.prod.yml` for production overrides but the file doesn't exist. Create it with CPU/memory limits per service (especially Ollama which can OOM-kill the host), restart policies, and read-only root filesystem where possible.
- [x] D2.7: Add missing test coverage for encryption roundtrip, auth flow, Shamir split/reconstruct, and connections -- Tests exist for vault, search, embedding, heartbeat, and ingestion but there are no dedicated `test_encryption.py` (envelope encrypt/decrypt roundtrip, wrong-key rejection, algo validation), `test_auth.py` (login/logout/session-timeout), `test_shamir.py` (split/reconstruct/threshold-failure), or `test_connections.py` (connection discovery, relationship extraction). Add these with edge cases.
- [x] D2.8: Implement optional cloud LLM fallback in llm.py -- There's a `TODO: optional cloud API fallback (OpenAI-compatible endpoint)` comment. When Ollama is unavailable, all AI features (chat, embeddings, connection generation) fail completely. Add config options for an OpenAI-compatible fallback endpoint (`FALLBACK_LLM_URL`, `FALLBACK_LLM_API_KEY`) with automatic failover and health-based routing.

## Discovery Round 3

- [x] D3.1: Replace assert statements with proper error handling in `backend/app/routers/ingest.py` -- Lines 221-222 and 309-310 use `assert` to validate that `title_envelope` and `content_envelope` are not None. Assertions are stripped when Python runs with `-O` (optimize) flag in production, turning these into silent no-ops. Replace with explicit `if ... is None: raise HTTPException(status_code=422, detail="Encryption envelope missing")`.
- [x] D3.2: Persist heartbeat challenges to database instead of in-memory dict -- `backend/app/services/heartbeat.py` line 44 stores pending challenges in `self._pending_challenges: dict[str, datetime]` which is lost on server restart. If the server restarts between challenge generation and check-in verification, the owner cannot complete their heartbeat. Store challenges in a database table with expiry timestamps.
- [x] D3.3: Implement `services/git_ops.py` for memory version history -- ARCHITECTURE.md §4 specifies `services/git_ops.py` for git version tracking, and `requirements.txt` includes `GitPython>=3.1`, but the file does not exist and no git operations are performed anywhere in the codebase. Memories have a `git_commit` field that is never populated. Implement git commit on memory create/update, storing the commit SHA on the Memory record.
- [x] D3.4: Create `models/tag.py` and implement tagging system -- ARCHITECTURE.md §4 specifies `models/tag.py` for tags and categories but the file does not exist. No tag model, no tag CRUD endpoints, and no tag-based filtering exists. The metadata_encrypted field could hold tags but there is no structured tagging workflow. Implement a Tag model, many-to-many relationship with Memory, and tag CRUD endpoints.
- [x] D3.5: Use a dedicated JWT secret instead of reusing `auth_salt` -- `backend/app/routers/auth.py` lines 51, 64, 71 use `settings.auth_salt` as the JWT signing secret. The auth_salt is the Argon2id salt shared with the client for key derivation; if it leaks (it's sent to the browser during login), an attacker can forge JWT sessions. Add a separate `JWT_SECRET` config value (auto-generated in `scripts/init.sh`) used only for token signing.
- [x] D3.6: Add connection explanation display to frontend Graph and MemoryDetail components -- `frontend/src/types/index.ts` defines `explanation_encrypted` and `explanation_dek` on the Connection type, and the backend returns these fields, but no frontend component ever decrypts or displays them. Users cannot see why AI connected two memories. Add explanation decryption and display on hover/click in Graph.tsx and as a detail section in MemoryDetail.tsx.
- [x] D3.7: Implement `services/backup.py` for programmatic backup orchestration -- ARCHITECTURE.md §4 specifies `services/backup.py` for backup orchestration but the file does not exist. The `scripts/backup.sh` handles backup from the host, but there is no API endpoint to trigger or monitor backups, and the health endpoint cannot report backup status. Create the service with last-backup-time tracking and a `/api/backup/status` endpoint.
- [x] D3.8: Add `nodev` flag to Qdrant and Ollama health checks and fix Alpine bash dependency -- `docker-compose.yml` lines 65 and 80 use `bash -c 'echo > /dev/tcp/...'` for health checks, but Alpine-based images (Qdrant uses Alpine) may not have bash. Replace with `wget --spider` or `curl` based checks. Also standardize health check format across all services (backend uses CMD+curl, others use CMD-SHELL+bash).

## Discovery Round 4

- [x] D4.1: Add missing `source_id` foreign key field to Memory model -- ARCHITECTURE.md §5.1 specifies `source_id: str | None = None  # FK to Source (original file in vault)` on the Memory model, but `backend/app/models/memory.py` does not have this field. This breaks the documented relationship between Memory and Source: when a file is ingested and stored in the vault, there is no way to link the Memory record back to its Source record via a direct FK. Add `source_id` field with `foreign_key="sources.id"` to Memory and corresponding fields to MemoryCreate/MemoryRead schemas.
- [x] D4.2: Enforce `MAX_UPLOAD_SIZE_MB` in frontend file upload handler -- `frontend/src/components/Capture.tsx` defines `MAX_UPLOAD_SIZE_MB = 500` (line 31) and displays it to users (line 237), but never actually validates file size before uploading. Users can attempt arbitrarily large uploads that will fail on the backend, wasting bandwidth and causing confusing errors. Add an explicit size check in `handleFileUpload()` before calling `uploadFileWithProgress()`.
- [x] D4.3: Add React ErrorBoundary to prevent full-app white-screen crashes -- No ErrorBoundary component exists anywhere in `frontend/src/`. An uncaught error in any component (e.g., a decryption failure, malformed API response, or graph rendering error) crashes the entire app with a blank white screen and no recovery path. Create an ErrorBoundary wrapper in `App.tsx` that catches render errors, displays a fallback UI with the error message, and offers a "reload" button.
- [x] D4.4: Add rate limiting to Caddyfile for API routes -- ARCHITECTURE.md §10.3 specifies "Rate limiting at Caddy level (100 req/min per IP)" but the `Caddyfile` has no rate limiting configuration. Without it, the API is vulnerable to brute-force passphrase attempts and denial-of-service. Add `rate_limit` directive to `/api/*` routes using Caddy's built-in rate limiting module.
- [x] D4.5: Add WebSocket reconnection with exponential backoff in Chat component -- `frontend/src/components/Chat.tsx` creates a WebSocket connection on mount but has no automatic reconnection logic. If the backend restarts or the network briefly drops, users must manually refresh the entire page to restore chat. Implement exponential backoff retry (1s, 2s, 4s, 8s, max 30s) with a visible "Reconnecting..." indicator and a manual "Reconnect" button.
- [x] D4.6: Add fallback LLM configuration prompts to `scripts/init.sh` -- The `.env.example` documents 4 optional cloud LLM fallback variables (`FALLBACK_LLM_URL`, `FALLBACK_LLM_API_KEY`, `FALLBACK_LLM_MODEL`, `FALLBACK_EMBEDDING_MODEL`) and `backend/app/config.py` supports them, but `scripts/init.sh` never prompts for or writes these variables during setup. Users must manually edit `.env` to enable cloud fallback. Add an optional fallback LLM configuration section to the interactive setup wizard.
- [x] D4.7: Create frontend tag management UI -- Backend has a complete tagging system (`models/tag.py`, `routers/tags.py`) and `frontend/src/types/index.ts` defines `Tag` and `MemoryTag` interfaces, but no frontend component allows users to create, assign, or filter by tags. Add tag chips to Capture.tsx (assign on create), MemoryDetail.tsx (view/edit tags), and a tag filter to Timeline.tsx and Search.tsx.

## Discovery Round 5

- [x] D5.1: Add manual captured_at date editing in MemoryDetail -- The LLM auto-extracts historical dates during ingest but may get them wrong, and there is no way for the user to correct `captured_at` from the UI. Add an editable date picker to `frontend/src/components/MemoryDetail.tsx` that lets the user view and override `captured_at`. The PUT `/api/memories/{id}` endpoint already accepts `captured_at` in the `MemoryUpdate` schema, so only frontend changes are needed: a date input field (defaulting to the current `captured_at`), a save button that calls `updateMemory()` with the new date, and optimistic UI update. After saving, refresh timeline stats if on the Timeline page.

- [x] D5.2: Add bulk file import with progress tracking -- Users need to import many old files (emails, photos, documents) at once. Add a bulk import flow: in `frontend/src/components/Capture.tsx`, allow selecting multiple files (via file picker or drag-and-drop), show a queued file list with individual progress bars, upload files sequentially (to avoid overwhelming the backend/Ollama), show per-file status (pending/uploading/processing/done/error), and a summary when complete. Reuse the existing `uploadFileWithProgress()` API function. Add a total progress indicator and the ability to cancel remaining uploads.

- [x] D5.3: Auto-refresh timeline bar after memory creation -- After uploading a new memory from the Capture page or after the background worker updates `captured_at`, the Timeline page's year bar is stale until the user manually refreshes. Fix this by: (1) refetching timeline stats when the Timeline component regains focus (via `document.addEventListener('visibilitychange')`), and (2) adding a lightweight refresh button/icon next to the timeline bar header. Do NOT use polling -- only refresh on visibility change and explicit user action.

- [x] D5.4: Make the UI responsive for mobile devices -- The current layout uses a fixed sidebar that doesn't adapt to small screens. Make the app usable on phones: (1) Convert the sidebar in `frontend/src/components/Layout.tsx` to a collapsible hamburger menu on screens below `md` breakpoint (768px). (2) In `Timeline.tsx`, make the TimelineBar horizontally scrollable on narrow screens and ensure memory cards stack properly. (3) In `Capture.tsx`, make the drag-and-drop zone and form inputs full-width on mobile. (4) In `Chat.tsx`, ensure the chat input stays fixed at the bottom on mobile keyboards. Use only Tailwind responsive prefixes (`sm:`, `md:`, `lg:`) -- no CSS modules or media queries.

## Discovery Round 6

- [ ] D6.1: Add PDF text extraction to preservation service -- Currently `application/pdf` is marked as already-archival in `_ARCHIVAL_MIMES` so PDFs pass through with NO text extraction (`text_extract=None`). This means uploaded PDFs are stored in the vault but their content is never indexed, searchable, or embeddable. Fix: (1) Add `pdfplumber` to `backend/requirements.txt`. (2) In `backend/app/services/preservation.py`, remove `application/pdf` from `_ARCHIVAL_MIMES` so it enters the conversion path. (3) Add a `_extract_pdf_text()` method that uses pdfplumber to extract text from all pages, concatenating into a single string. (4) Add a PDF handler block in `convert()` (after the document block) that returns the original PDF bytes unchanged as `preserved_data` (no format conversion needed) but populates `text_extract` with the extracted text. (5) Update `PRESERVATION_MAP` entry for `application/pdf` from `"pdf"` to `"pdf+text"` to indicate text extraction is performed. (6) Add `pdfplumber` to the backend Dockerfile if not already installed. (7) Handle edge cases: encrypted/password-protected PDFs (log warning, return None text_extract), scanned image-only PDFs (text_extract will be empty string — acceptable for now, OCR is a future enhancement).

- [ ] D6.2: Add legacy DOC and RTF support to preservation service -- The preservation service handles DOCX (via pandoc) but not legacy `.doc` (application/msword) or `.rtf` (application/rtf) files. Users with old documents need these formats supported. Fix: (1) Add `application/msword` and `application/rtf` entries to `PRESERVATION_MAP` with value `"pdf-a+md"`. (2) Add `.doc` and `.rtf` entries to `_MIME_INPUT_EXT`. (3) The existing `_convert_document()` method uses pandoc which already supports DOC and RTF input — just add the MIME types to the dispatch block in `convert()` alongside the existing OOXML types. (4) Add `application/msword` and `application/rtf` to the `_categorize_mime()` function in `backend/app/services/ingestion.py` so they map to content_type `"document"`. (5) Verify pandoc in the backend Docker image supports DOC format (it uses LibreOffice as a backend for DOC — may need `libreoffice-writer` installed in the Dockerfile). If LibreOffice is too heavy, use `antiword` for DOC→text as a lighter alternative and document the trade-off.

- [ ] D6.3: Re-process existing PDFs that were uploaded without text extraction -- The 3 PDFs already uploaded have no text extract (they were ingested before D6.1). Add a one-time migration/reprocessing endpoint: (1) Create `POST /api/admin/reprocess-sources` endpoint in a new `backend/app/routers/admin.py`. (2) The endpoint queries all Source records where `text_extract_encrypted IS NULL` and `mime_type = 'application/pdf'` (or any newly-supported type). (3) For each, retrieve the original file from the vault, run it through the updated preservation service to extract text, encrypt the text extract, update the Source record with `text_extract_encrypted` and `text_extract_dek`, and trigger search token generation + embedding for the new text. (4) Return a summary of how many sources were reprocessed. (5) Add a "Reprocess" button in the Settings page that calls this endpoint with a progress indicator.

- [ ] D6.4: Add inline document viewer to MemoryDetail for PDFs and Office documents -- When viewing a document-type memory in `frontend/src/components/MemoryDetail.tsx`, the user only sees extracted text — there is no way to view the actual file. Fix: (1) In the `useEffect` that fetches vault files, expand the condition from `content_type === "photo"` to also handle `"document"`. (2) For PDFs (`mime_type === "application/pdf"` or preserved format is PDF): fetch the vault file via `fetchVaultFile()`, create an object URL, and render it in an `<iframe>` or `<object>` tag with `type="application/pdf"` — browsers have built-in PDF viewers that handle this natively. Style the viewer with a fixed height (e.g. `h-[600px]`) and full width, with a rounded border matching the app theme. (3) For DOCX/DOC files that were converted to PDF by the preservation service: fetch the *preserved* copy (which is the PDF) from the vault rather than the original, and render it in the same PDF viewer. This requires adding a `fetchPreservedVaultFile(sourceId)` API function if one doesn't exist, or using the existing vault endpoint with a query param to select the preserved copy. (4) Add a "Download Original" button below the viewer that lets the user download the original file (DOC/DOCX/PDF) to their device. (5) Add a fallback message if the browser cannot render the PDF inline: "Your browser doesn't support inline PDF viewing" with a download link. (6) Keep the existing text extract display below the viewer — it serves as a searchable/readable version of the content.

- [ ] D6.5: Add OCR text extraction for scanned/image-only PDFs and photos -- D6.1 extracts text from PDFs using pdfplumber, but scanned PDFs (which are just embedded images) and photos of documents produce empty or no text extracts, making them unsearchable. Fix: (1) Add `pytesseract` to `backend/requirements.txt` and install `tesseract-ocr` plus language packs (`tesseract-ocr-eng` at minimum) in the backend Dockerfile via `apt-get`. (2) In `backend/app/services/preservation.py`, add an `_ocr_extract_text()` method that takes image bytes (PIL Image), runs `pytesseract.image_to_string()`, and returns the extracted text (stripped/cleaned). (3) In the PDF handler (added by D6.1): after pdfplumber text extraction, if the result is empty or near-empty (e.g. less than 50 characters total across all pages), fall back to OCR — render each PDF page to an image using `pdfplumber`'s `.to_image()` or `pdf2image`/`poppler` and run tesseract on each page image, concatenating the results. Add `pdf2image` to requirements.txt and `poppler-utils` to the Dockerfile if using pdf2image for rendering. (4) For photo-type memories (`content_type === "photo"`): after image preservation (conversion to PNG), run OCR on the preserved image. If OCR produces meaningful text (more than ~20 characters), store it as `text_extract` so photos of documents, receipts, whiteboards, etc. become searchable. (5) Add a config flag `OCR_ENABLED=true` in `.env.example` and `backend/app/config.py` so OCR can be disabled if tesseract is not installed or the user doesn't want the overhead. (6) OCR can be slow — log processing time and consider running it in the background worker rather than inline during ingest if it exceeds a threshold (e.g. 10 seconds). (7) Update the D6.3 reprocessing endpoint to also re-process photos and image-only PDFs that have no text extract, triggering OCR on them.
